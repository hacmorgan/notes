* TODO Longer term TODOs
** TODO [#A] metashape-cli-backend: die if metashape version too old
** TODO [#A] how-to lantern-photogrammetry: implement Thomas' changes
** TODO [#B] metashape-cli: predefined expressions
*** DONE change --print-predefined-expressions to --pretty-print-expressions
*** DONE add --print-expressions,-p to print expressions as they are defined
*** TODO investigate predefined expressions with values
** TODO [#B] metashape-cli: add examples
** TODO [#B] metashape-cli: write command (incl. substituted expression) to a file
** TODO [#B] metashape-cli: die if no expression given
** TODO [#C] lantern-photogrammetry: autoset seqview to Camera On Demand
** TODO [#C] metashape-cli: add --list-export-filetypes (for mesh and pointcloud)
** TODO [#C] fix bruno .tmux.conf (or whatever is causing autosuggestions to not work)
* Week starting <2020-12-21 Mon>
** <2021-01-04 Mon> - LEAVE
** <2021-01-05 Tue> - fix lantern-photogrammetry; review video-gen; ADK005 processing
*** TODO branch bedrock and integrate metashape-cli for 1.6.5 compatibility
*** DONE email zdzislaw to tee up a time for review
*** TODO look into adk005 processing
Look at the datasets, read Jordan's notes

** <2021-01-06 Wed> - finish lantern-photogrammetry fix; ADK005 testing
*** DONE finish fixing lantern-photogrammetry
This will involve fixing metashape-cli, as we are still getting /RuntimeError: not enough cameras/
-> caused by not appending .psx for metashape-cli process
*** TODO test reconstruction with 3 links at a time
There should be some processed data on Pond, start there.
- seqview was down! Took some work to make a local instance
- got up to labelling, will talk to asif tomorrow
*** TODO set up local seqview instance
- add prefs folder in root directory of seqview
** <2021-01-07 Thu> - ADK005 testing
*** DONE fix directory structure
*** DONE generate seqview data for mooring line 1
** <2021-01-08 Fri> - ADK005 testing; investigate thing for Fraser
*** TODO create or update masking SOP
*** TODO investigate thing for Fraser
*** TODO mask revolutions separately in V7
- Lots of bash loops! I should save these commands I'm using...
- While it's a bit tedious keeping everything in order, it should be easy enough to separate the work out.
- Definitely a big job uploading data to V7 like this
  - It would be nice if uploads from command line preserved folders
**** TODO rename to adk005.mooring-line-1, as we will put all the links in this project
*** TODO generate imagery with darktable filter
*** DONE investigate reconstruction without masks
Not good :(

* Week starting <2021-01-11 Mon>
** <2021-01-11 Mon> - ADK005 meeting & masking
*** ADK005 deliverables meeting
- We have previous data from the client:
  - caliper measurements
  - previous photogrammetry work
- We want to be able to merge this previous data with our data
*** ADK005 masking
*** TODO run 1st model /without/ colour correction
*** TODO run 1st model /with/ colour correction
*** TODO investigate thing for Fraser
*** TODO modify lea-preprocess aggregate-logs (or create new function) to merge revolutions
** <2021-01-12 Tue> - ADK005 testing
*** DONE fix metashape-cli masking
*** DONE investigate adding darktable functionality to metashape-cli
For now, it is probably worth keeping this out. It is still handled in =lantern-photogrammetry=, and there are many other things that could be automated if we continue working like this.
*** DONE clean up ADK005 datasets
*** DONE investigate thing for Fraser
*** TODO run batch processing experiments
** <2021-01-13 Wed> - ADK005 testing
*** TODO metashape-cli: --chunk-num -> --chunk-id
** <2021-01-14 Thu> - ADK005 data upload, testing
*** DONE remove the /redo/ datasets
*** DONE split ml2-pos-19 into two datasets
*** DONE make colour corrected versions of all the images from ml1 and ml2
** <2021-01-15 Fri> - ADK005 testing
*** DONE process pos-2 separately
*** DONE downsample all images
* Week starting <2021-01-18 Mon>
** <2021-01-18 Mon> - ADK005 workflow development; OCN001 image selection
*** TODO check all of the ML1 imagery for overexposure, correct it all
Maybe check with Thomas
*** TODO process some of the OCN001 data again
*** TODO review line-1 masks
**** folders with images that ened re-annotating
- pos-23/camera-1
- pos-22/camera-1
- pos-21/camera-1
*** TODO clean up line 1 processed revolutions' directory structures
** <2021-01-19 Tue> - ADK005 single link testing; OCN001 selection
*** DONE see what was wrong with bash command
*** DONE move files to correct place
*** DONE symlink all corrected images
*** DONE run metashape
*** DONE [#A] check downscaled alignment model
*** DONE [#B] clean jordan's model
*** DONE [#C] export a texture
*** DONE queue up some other processing experiments
*** DONE maybe investigate the camera alignment improving stuff from old lantern-photogrammetry
*** DONE try with different limits for tiepoints
** <2021-01-20 Wed> - ADK005 STILL NOT WORKING FFS (jk it is)
*** TODO rerun jordan's dataset with 1.6.5 (incl. darktable)
*** TODO take the return trip out (only half the revolutions)
*** TODO try other links
*** DONE send bp004 email & Jordan's model to all concerned
*** TODO see if checked scalebars have any impact with reference_preselection=False 
*** TODO check when scalebars are turned on in the pipeline
*** TODO re-upscale the masks for link 1 (SCRIPT IT)
*** DONE change all masks and images directories to read only (SCRIPT IT) 
*** TODO fix bad alignment accuracy
**** TODO try setting generic preselction to False
**** TODO try masking out the corners of the images (SCRIPT IT)
didn't script it, just did a find masks (etc)
*** TODO fix metashape-cli:
**** TODO default expressions
**** TODO turn off scalebars before alignment
** <2021-01-21 Thu> - ADK005 accuracy fixing
*** DONE set up batch processing script
*** DONE start batch processing
*** DONE check if images matched by scalebars are actually pairs
Yes, but some of their timestamps are off slightly.
Even if the pipeline blindly matches images, it should still work. All the images are good matches
*** TODO investigate how the processing tools make scalebars
*** TODO review ml2 V7 stuff
*** TODO add to the ADK005 data processing page
*** DONE (SCRIPT) remove all "images" folders
if images folder exists and images-uncorrected exists and images-corrected exists AND they all have the same number of images, delete images folder. Otherwise throw error
*** DONE regenerate ml4 data 
*** DONE generate comparison videos for all revolutions -> seqview 
- burn timestamp into image
- get help reviewing 
**** DONE make merged video work in seqview
check what's different between lantern-photogrammetry and platypus-explorer-calc
*** TODO maybe try a different /redo/ if there is a problem on that rev
- this could be caused by hanging in the GUI?
*** TODO bring lash up to speed
** <2021-01-22 Fri> - ADK005 comparison videos, ML2 review
*** DONE remove .local/bin bedrock utils
*** TODO fix how-to lantern-photogrammetry
*** DONE check all the comparison videos
*** TODO add to the ADK005 data processing page
*** TODO talk to Thomas about how to delegate some of this work
* Week starting <2021-01-25 Mon>
** <2021-01-25 Mon> - ADK005 masking review
*** TODO check other ML2 links
**** c-link: almost good, just a few misalignments
**** d-link: much the same
**** e-link: same again
*** TODO clean ML2 b-link
*** TODO review ML2 masks
*** TODO fix out-of-sync imagery
*** DONE fix ml2-pos-11 incorrect image
*** TODO maybe just check to make sure the ppms really are faulty
** <2021-01-26 Tue> - downloading V7 masks
wait for pos-21
** <2021-01-27 Wed> - ADK005 timestamp fixing
*** DONE make a csv for revolutions that need fixing
*** DONE make new directories in processed
*** DONE put the csv for correct image alignment in those directories
*** DONE re-annotate the seqview videos to only take one half of the revolution
*** DONE use seqview video + alignment csv to make a new images-uncorrected directory
- this should be scripted, and needs to drop lines without two comma-separated names
  - see if comma can handle this

*** DONE generate new comparison videos
*** DONE generate textured model for b-link
** <2021-01-28 Thu> - ADK005 V7 upload, monitoring cleaning of dense clouds
*** DONE ML1 shifted datasets: regen images-all
*** DONE check dense clouds for alignment issues
*** next time don't use V7 folders, just change file names to something recoverable
** <2021-01-29 Fri> - ADK005 masking reviewing, fix metashape-cli bug
*** DONE update data-processing-notes.md
**** non-downsampled aligned datasets
*** DONE fix metashape-cli bug
*** DONE email seva with bug
*** DONE check whether all downloaded masks are pngs
*** DONE ml4: make directories and revolutions.txt for each link
*** DONE symlink ml4 images & masks
*** DONE download ml1 a-link masks
*** DONE symlink ml1 a-link images
* Week starting <2021-02-01 Mon>
** <2021-02-01 Mon> - ML5 mask review, PSC bug fix
*** DONE Fix bugs in platypus-scout-calc
*** DONE Review ML5 masks
**** REMEMEBER TO MOVE RELEVANT IMAGES FROM pos-15/camera-0 TO pos-14/cammera-1!!!
Also confirm first whether this is correct
*** TODO run processing overnight
check whether ml2-a-link ran, as it was read-only, probably still open on buffalo
** <2021-02-02 Tue> - Polyworks
*** TODO none of the ML5 models had all the images symlinked 
*** DONE fix detect-checkerboard
*** TODO update story points on model generation
** <2021-02-03 Wed> - Perpendicular polyworks 
*** DONE make cross-sections perpendicular in Polyworks
*** TODO update story points on model generation
*** TODO check stuff that ran overnight
**** TODO check ml5 accuracies
**** TODO check scalebars as appropriate in all models and reset transform
**** TODO rerun all model generation
**** TODO check that scalebars remain 
*** DONE regenerate comparison videos
** <2021-02-04 Thu> - Polyworks measurements
*** DONE take all measurements for models with valid models
*** DONE compare measurements to caliper measurements
** <2021-02-05 Fri> - Fix ML5 B-link, more polyworks, polyowrks documentation, area of cross-sections
*** DONE fix out-of-sync images on the B-link
Jordan says dw
*** DONE run polyworks measurment workflow on remaining ML4 models, extract measurements, update sheet
*** TODO document the polyworks measurement workflow
*** TODO write a script to calc area of a cross-section
* Week starting <2021-02-08 Mon>
** <2021-02-08 Mon> - Final Polyworks
*** DONE Run polyworks workflow on ML5 models
*** DONE clean ML5 a-link textured model noise
*** TODO document the polyworks measurement workflow
*** TODO write a script to calc area of a cross-section
*** DONE polyworks revisions
**** DONE red arrow heads
**** DONE remove bottom bit (organization etc) as well as date and pg number
**** DONE export pages as high-res images
**** DONE remove underscores in names
**** DONE concatenate CSVs
** <2021-02-09 Tue> - PI
** <2021-02-10 Wed> - PI
** <2021-02-11 Thu> - ADK005 Extras
*** TODO ADK005 Extra Bits
**** TODO calculate change in measurements when rotating the cross-section +/- 5 degrees
**** TODO calculate change in measurements when rotating measurements +/- 5 degrees about the normal to the cross-section plane
**** TODO calculate area of all cross-sections for a single link, calculate ellipse area based on in & out of plane, compare
** <2021-02-12 Fri> - ADK005 wrap-up, 
*** TODO Polyworks workflow -> Confluence
*** DONE Metashape calibration/validation discussion -> Confluence
*** DONE verify that cross-section areas make sense visually (csv-plot!)
*** DONE re-export all points in case the cross-section picks up noise
* Week starting <2021-02-15 Mon>
** <2021-03-15 Mon> - Terrapin software dev practices, some polyworks documentation
*** TODO establish best practices for robotics team
** <2021-03-16 Tue> - Establish software best practices
Write documentation, etc
** <2021-02-17 Wed> - ROS-independent data format
*** DONE send email re: =lantern-photogrammetry=
*** TODO merge polyworks confluence pages
*** TODO get some example ROS bags
*** TODO test the relative efficiencies of binary and zstd compressed YAML
- with images stored this way too
**** TODO write a utility to convert our PPMs to text based for this comparison 
csv-{to,from}-bin are little-endian, but PPMs are big-endian :/
  

*** TODO review results with Zdzislaw
** <2021-02-18 Thu> - ROS-independent data format
*** DONE add email contents to confluence (lantern-photogrammetry)
*** DONE make a simple binary data structure to compare size
** <2021-02-19 Fri> - ROS-independent data format, helping Lash
*** TODO write C++ util to extract from bagfile to YAML
*** DONE nail down data format
big data (pointclouds, images, etc) stored externally, everything else: ROS bag -> yaml
*** TODO determine whether this package needs to be in our catkin workspace
*** TODO work out if it's a problem that ros-bag-to-bin is only compatible with melodic
* Week starting <2021-02-22 Mon>
** <2021-02-22 Mon> - ROS-independent data format
*** DONE Discuss ROS with Lash
If abyss-ros doesn't have to be built in order for the Python ROS API to work correctly, does that make a ROS bag an acceptable file format, at least for now? There are some reasons to stick with rosbags, e.g. to play them back in real time, etc.

We can use one or multiple external utilities (such as =ros-bag-to-bin=) that use the Python API to extract the data we need from the bags as necessary, which avoids the need for every utility along the way to parse YAMLs or bagfiles. Also, if we *do* go down this road of using YAMLs, we will be able to mimic =ros-bag-to-bin='s behaviour, just with YAMLs as input.

One important point from this is that in many cases, moving these utilities to parse a different format down the line would likely actually be quite simple.

Otherwise

*** DONE brush up =ros-to-csv= and maybe =ros-bag-to-bin=, to see how viable they are
get these utils working correctly, try to extract data from bagfiles of various ages

They are python2 utilities, and probably a little overfit for what we're doing. With some work we could get them working, but probably not worthwhile

*** DONE merge polyworks docs
** <2021-02-23 Tue> - ROS-independent data format cont'd
*** DONE decide on the format: *YAML*
*** TODO write yamlToCsv
The question here is speed. Will using the YAML library just spend ages loading and unloading memory?
If it does, we can maybe deal with just simple text parsing

*problem:* there exists no YAML parser that doesn't read the WHOLE file in order to do anything. Writing a parser is not difficult, but it is time-consuming
*** DONE merge master
** <2021-02-24 Wed> - YAML -> CSV 
*** TODO Write YAML to CSV 
** <2021-02-25 Thu> - YAML -> CSV
** <2021-02-26 Fri> - YAML -> CSV
* Week starting <2021-03-01 Mon>
** <2021-03-01 Mon> - YAML -> CSV
Reviewed Zdzislaw's changes over the weekend, now have a backlog of todos
*** DONE handle stdin
*** DONE write documentation
*** DONE clean up code structure and help function
*** TODO add more usage examples
*** TODO handle compression
*** TODO optimise construction of CSV data (is it any faster to print value-by-value?)
*** TODO export as binary
*** TODO use cmake instead
*** TODO write tests

