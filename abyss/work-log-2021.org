 Longer term TODOs
** TODO [#A] write up (on Confluence) plan to move lantern processing to python
Include Mitch in this process
** TODO [#A] Finish reviewing Mitch's changes
** TODO [#A] Write demob confluence page (JJ review)
** TODO [#A] metashape-cli-backend: die if metashape version too old
** TODO [#A] how-to lantern-photogrammetry: implement Thomas' changes
** TODO [#B] metashape-cli: add examples
** TODO [#B] metashape-cli: write command (incl. substituted expression) to a file
** TODO [#B] metashape-cli: die if no expression given
** TODO [#C] metashape-cli: predefined expressions
*** DONE change --print-predefined-expressions to --pretty-print-expressions
*** DONE add --print-expressions,-p to print expressions as they are defined
*** TODO investigate predefined expressions with values
** TODO [#C] lantern-photogrammetry: autoset seqview to Camera On Demand
** TODO [#C] metashape-cli: add --list-export-filetypes (for mesh and pointcloud)
** TODO [#C] fix bruno .tmux.conf (or whatever is causing autosuggestions to not work)
* Week starting <2020-12-21 Mon>
** <2021-01-04 Mon> - LEAVE
** <2021-01-05 Tue> - fix lantern-photogrammetry; review video-gen; ADK005 processing
*** TODO branch bedrock and integrate metashape-cli for 1.6.5 compatibility
*** DONE email zdzislaw to tee up a time for review
*** TODO look into adk005 processing
Look at the datasets, read Jordan's notes

** <2021-01-06 Wed> - finish lantern-photogrammetry fix; ADK005 testing
*** DONE finish fixing lantern-photogrammetry
This will involve fixing metashape-cli, as we are still getting /RuntimeError: not enough cameras/
-> caused by not appending .psx for metashape-cli process
*** TODO test reconstruction with 3 links at a time
There should be some processed data on Pond, start there.
- seqview was down! Took some work to make a local instance
- got up to labelling, will talk to asif tomorrow
*** TODO set up local seqview instance
- add prefs folder in root directory of seqview
** <2021-01-07 Thu> - ADK005 testing
*** DONE fix directory structure
*** DONE generate seqview data for mooring line 1
** <2021-01-08 Fri> - ADK005 testing; investigate thing for Fraser
*** TODO create or update masking SOP
*** TODO investigate thing for Fraser
*** TODO mask revolutions separately in V7
- Lots of bash loops! I should save these commands I'm using...
- While it's a bit tedious keeping everything in order, it should be easy enough to separate the work out.
- Definitely a big job uploading data to V7 like this
  - It would be nice if uploads from command line preserved folders
**** TODO rename to adk005.mooring-line-1, as we will put all the links in this project
*** TODO generate imagery with darktable filter
*** DONE investigate reconstruction without masks
Not good :(

* Week starting <2021-01-11 Mon>
** <2021-01-11 Mon> - ADK005 meeting & masking
*** ADK005 deliverables meeting
- We have previous data from the client:
  - caliper measurements
  - previous photogrammetry work
- We want to be able to merge this previous data with our data
*** ADK005 masking
*** TODO run 1st model /without/ colour correction
*** TODO run 1st model /with/ colour correction
*** TODO investigate thing for Fraser
*** TODO modify lea-preprocess aggregate-logs (or create new function) to merge revolutions
** <2021-01-12 Tue> - ADK005 testing
*** DONE fix metashape-cli masking
*** DONE investigate adding darktable functionality to metashape-cli
For now, it is probably worth keeping this out. It is still handled in =lantern-photogrammetry=, and there are many other things that could be automated if we continue working like this.
*** DONE clean up ADK005 datasets
*** DONE investigate thing for Fraser
*** TODO run batch processing experiments
** <2021-01-13 Wed> - ADK005 testing
*** TODO metashape-cli: --chunk-num -> --chunk-id
** <2021-01-14 Thu> - ADK005 data upload, testing
*** DONE remove the /redo/ datasets
*** DONE split ml2-pos-19 into two datasets
*** DONE make colour corrected versions of all the images from ml1 and ml2
** <2021-01-15 Fri> - ADK005 testing
*** DONE process pos-2 separately
*** DONE downsample all images
* Week starting <2021-01-18 Mon>
** <2021-01-18 Mon> - ADK005 workflow development; OCN001 image selection
*** TODO check all of the ML1 imagery for overexposure, correct it all
Maybe check with Thomas
*** TODO process some of the OCN001 data again
*** TODO review line-1 masks
**** folders with images that ened re-annotating
- pos-23/camera-1
- pos-22/camera-1
- pos-21/camera-1
*** TODO clean up line 1 processed revolutions' directory structures
** <2021-01-19 Tue> - ADK005 single link testing; OCN001 selection
*** DONE see what was wrong with bash command
*** DONE move files to correct place
*** DONE symlink all corrected images
*** DONE run metashape
*** DONE [#A] check downscaled alignment model
*** DONE [#B] clean jordan's model
*** DONE [#C] export a texture
*** DONE queue up some other processing experiments
*** DONE maybe investigate the camera alignment improving stuff from old lantern-photogrammetry
*** DONE try with different limits for tiepoints
** <2021-01-20 Wed> - ADK005 STILL NOT WORKING FFS (jk it is)
*** TODO rerun jordan's dataset with 1.6.5 (incl. darktable)
*** TODO take the return trip out (only half the revolutions)
*** TODO try other links
*** DONE send bp004 email & Jordan's model to all concerned
*** TODO see if checked scalebars have any impact with reference_preselection=False 
*** TODO check when scalebars are turned on in the pipeline
*** TODO re-upscale the masks for link 1 (SCRIPT IT)
*** DONE change all masks and images directories to read only (SCRIPT IT) 
*** TODO fix bad alignment accuracy
**** TODO try setting generic preselction to False
**** TODO try masking out the corners of the images (SCRIPT IT)
didn't script it, just did a find masks (etc)
*** TODO fix metashape-cli:
**** TODO default expressions
**** TODO turn off scalebars before alignment
** <2021-01-21 Thu> - ADK005 accuracy fixing
*** DONE set up batch processing script
*** DONE start batch processing
*** DONE check if images matched by scalebars are actually pairs
Yes, but some of their timestamps are off slightly.
Even if the pipeline blindly matches images, it should still work. All the images are good matches
*** TODO investigate how the processing tools make scalebars
*** TODO review ml2 V7 stuff
*** TODO add to the ADK005 data processing page
*** DONE (SCRIPT) remove all "images" folders
if images folder exists and images-uncorrected exists and images-corrected exists AND they all have the same number of images, delete images folder. Otherwise throw error
*** DONE regenerate ml4 data 
*** DONE generate comparison videos for all revolutions -> seqview 
- burn timestamp into image
- get help reviewing 
**** DONE make merged video work in seqview
check what's different between lantern-photogrammetry and platypus-explorer-calc
*** TODO maybe try a different /redo/ if there is a problem on that rev
- this could be caused by hanging in the GUI?
*** TODO bring lash up to speed
** <2021-01-22 Fri> - ADK005 comparison videos, ML2 review
*** DONE remove .local/bin bedrock utils
*** TODO fix how-to lantern-photogrammetry
*** DONE check all the comparison videos
*** TODO add to the ADK005 data processing page
*** TODO talk to Thomas about how to delegate some of this work
* Week starting <2021-01-25 Mon>
** <2021-01-25 Mon> - ADK005 masking review
*** TODO check other ML2 links
**** c-link: almost good, just a few misalignments
**** d-link: much the same
**** e-link: same again
*** TODO clean ML2 b-link
*** TODO review ML2 masks
*** TODO fix out-of-sync imagery
*** DONE fix ml2-pos-11 incorrect image
*** TODO maybe just check to make sure the ppms really are faulty
** <2021-01-26 Tue> - downloading V7 masks
wait for pos-21
** <2021-01-27 Wed> - ADK005 timestamp fixing
*** DONE make a csv for revolutions that need fixing
*** DONE make new directories in processed
*** DONE put the csv for correct image alignment in those directories
*** DONE re-annotate the seqview videos to only take one half of the revolution
*** DONE use seqview video + alignment csv to make a new images-uncorrected directory
- this should be scripted, and needs to drop lines without two comma-separated names
  - see if comma can handle this

*** DONE generate new comparison videos
*** DONE generate textured model for b-link
** <2021-01-28 Thu> - ADK005 V7 upload, monitoring cleaning of dense clouds
*** DONE ML1 shifted datasets: regen images-all
*** DONE check dense clouds for alignment issues
*** next time don't use V7 folders, just change file names to something recoverable
** <2021-01-29 Fri> - ADK005 masking reviewing, fix metashape-cli bug
*** DONE update data-processing-notes.md
**** non-downsampled aligned datasets
*** DONE fix metashape-cli bug
*** DONE email seva with bug
*** DONE check whether all downloaded masks are pngs
*** DONE ml4: make directories and revolutions.txt for each link
*** DONE symlink ml4 images & masks
*** DONE download ml1 a-link masks
*** DONE symlink ml1 a-link images
* Week starting <2021-02-01 Mon>
** <2021-02-01 Mon> - ML5 mask review, PSC bug fix
*** DONE Fix bugs in platypus-scout-calc
*** DONE Review ML5 masks
**** REMEMEBER TO MOVE RELEVANT IMAGES FROM pos-15/camera-0 TO pos-14/cammera-1!!!
Also confirm first whether this is correct
*** TODO run processing overnight
check whether ml2-a-link ran, as it was read-only, probably still open on buffalo
** <2021-02-02 Tue> - Polyworks
*** TODO none of the ML5 models had all the images symlinked 
*** DONE fix detect-checkerboard
*** TODO update story points on model generation
** <2021-02-03 Wed> - Perpendicular polyworks 
*** DONE make cross-sections perpendicular in Polyworks
*** TODO update story points on model generation
*** TODO check stuff that ran overnight
**** TODO check ml5 accuracies
**** TODO check scalebars as appropriate in all models and reset transform
**** TODO rerun all model generation
**** TODO check that scalebars remain 
*** DONE regenerate comparison videos
** <2021-02-04 Thu> - Polyworks measurements
*** DONE take all measurements for models with valid models
*** DONE compare measurements to caliper measurements
** <2021-02-05 Fri> - Fix ML5 B-link, more polyworks, polyowrks documentation, area of cross-sections
*** DONE fix out-of-sync images on the B-link
Jordan says dw
*** DONE run polyworks measurment workflow on remaining ML4 models, extract measurements, update sheet
*** TODO document the polyworks measurement workflow
*** TODO write a script to calc area of a cross-section
* Week starting <2021-02-08 Mon>
** <2021-02-08 Mon> - Final Polyworks
*** DONE Run polyworks workflow on ML5 models
*** DONE clean ML5 a-link textured model noise
*** TODO document the polyworks measurement workflow
*** TODO write a script to calc area of a cross-section
*** DONE polyworks revisions
**** DONE red arrow heads
**** DONE remove bottom bit (organization etc) as well as date and pg number
**** DONE export pages as high-res images
**** DONE remove underscores in names
**** DONE concatenate CSVs
** <2021-02-09 Tue> - PI
** <2021-02-10 Wed> - PI
** <2021-02-11 Thu> - ADK005 Extras
*** TODO ADK005 Extra Bits
**** TODO calculate change in measurements when rotating the cross-section +/- 5 degrees
**** TODO calculate change in measurements when rotating measurements +/- 5 degrees about the normal to the cross-section plane
**** TODO calculate area of all cross-sections for a single link, calculate ellipse area based on in & out of plane, compare
** <2021-02-12 Fri> - ADK005 wrap-up, 
*** TODO Polyworks workflow -> Confluence
*** DONE Metashape calibration/validation discussion -> Confluence
*** DONE verify that cross-section areas make sense visually (csv-plot!)
*** DONE re-export all points in case the cross-section picks up noise
* Week starting <2021-02-15 Mon>
** <2021-03-15 Mon> - Terrapin software dev practices, some polyworks documentation
*** TODO establish best practices for robotics team
** <2021-03-16 Tue> - Establish software best practices
Write documentation, etc
** <2021-02-17 Wed> - ROS-independent data format
*** DONE send email re: =lantern-photogrammetry=
*** TODO merge polyworks confluence pages
*** TODO get some example ROS bags
*** TODO test the relative efficiencies of binary and zstd compressed YAML
- with images stored this way too
**** TODO write a utility to convert our PPMs to text based for this comparison 
csv-{to,from}-bin are little-endian, but PPMs are big-endian :/
  

*** TODO review results with Zdzislaw
** <2021-02-18 Thu> - ROS-independent data format
*** DONE add email contents to confluence (lantern-photogrammetry)
*** DONE make a simple binary data structure to compare size
** <2021-02-19 Fri> - ROS-independent data format, helping Lash
*** TODO write C++ util to extract from bagfile to YAML
*** DONE nail down data format
big data (pointclouds, images, etc) stored externally, everything else: ROS bag -> yaml
*** TODO determine whether this package needs to be in our catkin workspace
*** TODO work out if it's a problem that ros-bag-to-bin is only compatible with melodic
* Week starting <2021-02-22 Mon>
** <2021-02-22 Mon> - ROS-independent data format
*** DONE Discuss ROS with Lash
If abyss-ros doesn't have to be built in order for the Python ROS API to work correctly, does that make a ROS bag an acceptable file format, at least for now? There are some reasons to stick with rosbags, e.g. to play them back in real time, etc.

We can use one or multiple external utilities (such as =ros-bag-to-bin=) that use the Python API to extract the data we need from the bags as necessary, which avoids the need for every utility along the way to parse YAMLs or bagfiles. Also, if we *do* go down this road of using YAMLs, we will be able to mimic =ros-bag-to-bin='s behaviour, just with YAMLs as input.

One important point from this is that in many cases, moving these utilities to parse a different format down the line would likely actually be quite simple.

Otherwise

*** DONE brush up =ros-to-csv= and maybe =ros-bag-to-bin=, to see how viable they are
get these utils working correctly, try to extract data from bagfiles of various ages

They are python2 utilities, and probably a little overfit for what we're doing. With some work we could get them working, but probably not worthwhile

*** DONE merge polyworks docs
** <2021-02-23 Tue> - ROS-independent data format cont'd
*** DONE decide on the format: *YAML*
*** TODO write yamlToCsv
The question here is speed. Will using the YAML library just spend ages loading and unloading memory?
If it does, we can maybe deal with just simple text parsing

*problem:* there exists no YAML parser that doesn't read the WHOLE file in order to do anything. Writing a parser is not difficult, but it is time-consuming
*** DONE merge master
** <2021-02-24 Wed> - YAML -> CSV 
*** TODO Write YAML to CSV 
** <2021-02-25 Thu> - YAML -> CSV
** <2021-02-26 Fri> - YAML -> CSV
* Week starting <2021-03-01 Mon>
** <2021-03-01 Mon> - YAML -> CSV
Reviewed Zdzislaw's changes over the weekend, now have a backlog of todos
*** DONE handle stdin
*** DONE write documentation
*** DONE clean up code structure and help function
*** TODO add more usage examples
*** TODO handle compression
*** TODO optimise construction of CSV data (is it any faster to print value-by-value?)
*** TODO export as binary
*** TODO use cmake instead
*** TODO write tests
** <2021-03-02 Tue> - Git migration, YAML -> CSV documentation
** <2021-03-03 Wed> - Git migration completion, YAML -> CSV documentation
*** *Performance when loading everything into memory*: 15m 58s to perform the below command
#+begin_src bash
./yaml-to-csv < ~/scratch/ros-independent-data-format/processed-data/platypus.points.yaml > /dev/null
#+end_src
*** *Performance when not loading scalars in sequences:* 12m
** <2021-03-04 Thu> - YAML -> CSV efficiency improvement
*** Testing efficiencies
- The following tests were performed on the file: /~/scratch/ros-independent-data-format/processed-data/platypus.points.yaml/
- stdout was redirected to //dev/null/ in all cases
|-----------------+---------------+--------------+---------|
| *sync_with_stdio* | *cout/cin tied* | *input stream* | *time*    |
|-----------------+---------------+--------------+---------|
| false           | false         | stdin        | 12m     |
| false           | false         | file         | 11m 26s |
| true            | false         | stdin        | 11m 6s  |
| true            | false         | file         | 11m 20s |
| false           | true          | stdin        |         |
| false           | true          | file         |         |
| true            | true          | stdin        |         |
| true            | true          | file         | 11m 16s |
|-----------------+---------------+--------------+---------|
** <2021-03-05 Fri> - YAML -> CSV
* Week starting <2021-03-08 Mon>
** <2021-03-08 Mon> - YAML -> CSV
*** DONE YAML -> CSV: handle scalars
*** DONE deactivate metashape
*** Testing efficiencies again
- This time, we are using file /~/scratch/ros-independent-data-format/processed-data/platypus.yaml/
  - It is 3.5G, where platypus.points.yaml is 2.2G. Scaling for this, the parsing time is on-par with what it was last time
- Still redirecting output to //dev/null/
|-------------+----------------+----------------|
| *yaml-to-csv* | *ros-bag-to-csv* | *ros-bag-to-bin* |
|-------------+----------------+----------------|
| 18m 20s     |                |                |
| 18m 02s     |                |                |
|             |                |                |
** <2021-03-09 Tue> - YAML -> CSV tidying up before review
*** TODO activate metashape on buffalo
*** TODO 
** <2021-03-10 Wed> - Sprint demo, installing stuff on buffalo, unit tests
** <2021-03-11 Thu> - Unit test debugging, V7 AI test, 
*** TODO fix segfaulting in unit testing
*** TODO test this new V7 feature
*** TODO change calibration page to say abyss-robotics
** <2021-03-12 Fri> - Same as above
* Week starting <2021-03-15 Mon>
** <2021-03-15 Mon> - Metashape spool piece test, fix private/public unit tests, V7 AI test complete
** <2021-03-16 Tue> - Finish writing unit tests
** <2021-03-17 Wed> - Platypus data validation: multiprocessing framework
** <2021-03-18 Thu> - ribf-to-csv: fix bugs and implement ZSL's changes; platypus data validation: image numbers in bags
*** DONE reset to before merging master
reset and push both need --force
*** TODO add Color to namespace Abyss
*** TODO add const and & to color functions
*** TODO constexp: read up on
** <2021-03-19 Fri> - email ras about bamboo
* Week starting <2021-03-22 Mon>
** <2021-03-22 Mon> - Implement Zdzislaw's feedback on ribf-to-csv
** <2021-03-23 Tue> - Platypus data validation
*** DONE Determine best format -> YAML
*** DONE Ensure program runs with yaml as config (instead of json)
* Week starting <2021-03-29 Mon>
** <2021-03-31 Wed> Meeting with Bentley re: ContextCapture, siq day
*** Bentley Meeting
- ContextCapture is similar to Metashape in functionality
- ContextCapture was an acquisition
  - Their main deal is software for big industries
- ContextCapture is supposedly *higher accuracy* and fidelity than Metashape
- Engine written for linux (driven by people using AWS)
  - Python SDK (runs on Linux)
  - No equivalent frontend yet (would need to use Windows)
- Pointclouds can be exported for cleaning before being re-imported for later stages
- Get back to Glen re: what kind of dataset we would test with
**** Questions
** <2021-04-01 Thu> Tunnel 3D modelling, email re: bentley, small things
*** DONE Send email re: Bentley ContextCapture
*** TODO Get reacquainted with tunnel modelling workflow
- Disregard run-01 downstream
- Range/frequency changes mid-run
  - check if this can be picked up by oculus-cat --info
  - make sure video gen utility can handle this
*** TODO Fix small things with yaml-to-csv
* Week starting <2021-04-05 Mon>
** <2021-04-08 Thu> Canal bathymetry
*** TODO generate canal bathymetry
*** TODO overlay sonar-to-points output on fan-view
** <2021-04-09 Fri> Canal bathymetry
*** TODO show points next to sonar fan view
- look through video for good parts, note timestamp: *20210324T035900*
- extract that exact record, run it through sonar-to-points
*** TODO refactor code for readability
*** TODO verify whether oculus-cat --info produces the same number of records as oculus-cat
**** TODO If so, change logic to give sonar-to-points the correct input each time
*** TODO roll everything into extract-sonar (maybe rename it)
**** TODO Keep its mapping and usage semantics, but keep logic from generate-sonar-video
*** TODO change format of pointclouds (convert to CSV and PCD)
*** TODO Work out what's causing accordian problem
One point from the problem zone:
=20210326T003057.640000,1316,-133.382487549732,152.3867340541208,3.151806875855458=
This file is the culprit:
//mnt/pond/datasets/ghd/balickera-canal/20210325-insepction/inspections/day-02/downstream-canal/centre-run-01/platypus-01/sonar/Oculus_20210326_002928.oculus/
start: 20210326T003054.392000
end:   20210326T003057.985000
* Week starting <2021-04-12 Mon>
** <2021-04-12 Mon> - Fix sonar issues, documentation
*** DONE Make a patched interim /sonar.bin/ with aberration fixed
- Run only on specified file
- Have a way of generating the plot of timestamps
**** This worked, but let's check a few other things:
- There is a step later in the run too, is that there in the original data?
  - If so, fix it too
*** TODO Regenerate downstream pointcloud
*** TODO Write some documentation
*** TODO Clean up code
*** TODO Process upstream canal
*** TODO Understand the new platform config
** <2021-04-13 Tue> - Neaten code
*** DONE Fix hole patching logic
*** DONE Move all code into examples
*** DONE fix platform config
*** DONE remove code from projects, replace with a README
** <2021-04-14 Wed> - Upstream canal, small lantern-photogrammetry fix, docs
*** DONE lantern-photogrammetry: add check for seqview-annotations
*** DONE Convert new pointcloud to CSV and PCD
- Also make these files read-only
*** TODO Verify whether these files are ready for submission to the client
** <2021-04-15 Thu> - Upstream canal, investigate cv-cat issues, abyss-robotics build
*** TODO Upstream canal processing
*** TODO Investigate Fraser's issue with cv-cat viewing 
Install an 18.04 VM
*** DONE Discuss the mid-log parameter changes with Lash & Zdzislaw
*** DONE fix the git commit template, update if it is on confluence
*** DONE abyss-robotics build system
*** TODO Document brute force test thing (in readme in projects)
** <2021-04-16 Fri> - Try to improve pointcloud, 
*** TODO pointcloud polishing
**** TODO clean left and right individually
**** TODO merge
**** TODO implement manual fixed roll to localisation 
try -2 degrees
*** TODO metashape-cli: investigate depth maps quality parameter (default=4????)
*** TODO Investigate a simpler parameter system for quality
- Maybe reinstate configs
- Otherise add flags
*** TODO abyss-validate python 3.6 compatibility
*** TODO abyss-validate add --machine-directory
- --machine-directory and (--bag-directory and --image-directory are mutually exclusive)
* Week starting <2021-04-19 Mon>
** <2021-04-19 Mon> - More pointcloud polishing, lantern util bugfixes, validator bugfixes
*** DONE Add artificial roll to pointclouds and check results
*** TODO try to +black out+ or crop the top of the sonar image
*must set --min-range for sonar-to-points.py* in order to crop
**** DONE try only setting min range, not doing cv-cat crop
Yep, that's good
**** TODO play with this live, see if --max-range and --min-range can help to maximise the quality of the PC
*** TODO generate lidar data too, view in CC
*** TODO Make abyss-validate Ubuntu 18.04 compatible
*** TODO abyss-validate: add --machine-directory
** <2021-04-20 Tue> - new localisation, LiDAR data, abyss-validate testing
*** TODO try to +black out+ or crop the top of the sonar image
*must set --min-range for sonar-to-points.py* in order to crop
**** DONE try only setting min range, not doing cv-cat crop
Yep, that's good
**** TODO play with this live, see if --max-range and --min-range can help to maximise the quality of the PC
*** TODO generate lidar data too, view in CC
*** TODO Make abyss-validate Ubuntu 18.04 compatible
*** TODO abyss-validate: add --machine-directory
*** DONE take measurements on lab wood
*** TODO Investigate Fraser's issue with cv-cat viewing 
Install an 18.04 VM
** <2021-04-21 Wed> - Clean pointclouds, abyss-validate, calibration, lab wood
*** DONE clean up pointclouds, review
*** DONE take measurements on lab wood
*** DONE housekeep fraser's calibration
*** TODO Make abyss-validate Ubuntu 18.04 compatible
*** TODO abyss-validate: add --machine-directory
*** TODO generate LiDAR data differently
Looks like sometimes the data field is longer than expected, investigate this further
*** TODO maybe investigate --crop-{left,right} for process-sonar
** <2021-04-22 Thu> - centre run tuning
*** TODO ? try centre run with different rotation
*** TODO ? try cropping left and right
*** TODO document the commands used for pointcloud generation 
*** TODO export pointclouds
*** TODO GHD report polish
**** DONE new side-by-side of sonar image and points
**** DONE update links
**** DONE enw screenshots ortho and persp
**** DONE video noise screenshot
**** DONE less/more sparse regions screenshot
** <2021-04-23 Fri> - bugfixes for validator
* Week starting <2021-04-26 Mon>
** <2021-04-26 Mon> - ContextCapture evaluation, pull requests
*** Fix problems and submit PR for data validation
**** DONE add readme
**** DONE add setup.py
** <2021-04-27 Tue> - PR responses, more ContextCapture
** <2021-04-28 Wed> - Respond to my PR, review ZSL's PR, more ContextCapture, investigate cv-cat bugfixes
*** TODO finish responding to ZSL's feedback
*** TODO review ZSL's PR
*** TODO rerun ContextCapture with 1.1" sensor size
*** TODO run Metashape with equivalent params
*** TODO compare ContextCapture with Metashape 
** <2021-04-29 Thu> - Complete data validation PR, review ros integration PR, CC evaluation
*** Data validation PR
Should have a call with ZSL to discuss:
- Where would our generic code go 
  - Abyss to iso format
  - colour code from ribf-to-csv
- mmap
- Python autoformatting
- oculus-cat: how to handle variable length binary data from other scripts/utilities
** <2021-04-30 Fri> - CC eval, fix lantern-get bug, call ZSL
*** TODO ContextCapture evaluation
- Run on highest settings on buffalo, compare results
- add notes about 23hr and random stopping to confluence
*** DONE Fix lantern-get bug
*** TODO Call ZSL to discuss:
x Where would our generic code go 
  - Abyss to iso format
  - colour code from ribf-to-csv
x mmap
  - try it!
x Python autoformatting
  x read comparison
  x add to confluence
x oculus-cat: how to handle variable length binary data from other scripts/utilities
  - one scan per file is easiest
x update_all.sh
  x compile a list of thing (in abyss-robotics) that we want to build
  - tie into CI/CD
  - what to do next
* Week starting <2021-05-03 Mon>
** <2021-05-03 Mon> - ADK005 report, CCEval, PRs
*** DONE Send email re: lantern-get bug
*** DONE ADK005 report updates
**** DONE make a diagram demonstrating the point
**** DONE copy to buffalo and commit projects
*** DONE ContextCapture evaluation
**** DONE Update confluence
**** DONE export everything as 3MX, fix names, move to pond
**** DONE Send an enail to Steve (CC Lash)
**** DONE Run carpark dataset with CC
copy output OBJ to pond
*** TODO investigate mmap for efficiency improvements
*** TODO submit a PR to bedrock with generic code
- model it after comma (if that is sensible)
- Tag or mention team leads to notify them of this code
*** DONE implement ZSL's changes to robotics-validate
** <2021-05-04 Tue> - LEAVE (Emily's graduation)
** <2021-05-05 Wed> - robotics-validate pull request follow-up
*** TODO Investigate mmap for validator
- Currently we go through the =rosbag.Bag(filename)= interface, so will need to see whether we can maintain functionality using an interface with a Python file object
- *You can give rosbag.Bag a file object, yay!*
  - Unfortunately it isn't happy with that just yet
*** DONE Write paragraph on how calipers work (comment no. 14 in [[https://docs.google.com/spreadsheets/d/1RCnDb6uR4q6Kj4r8ykb1TSGiYrUtZl1LKL5jo1d9Isw/edit#gid=0][this document]])
*** DONE Send explanation to Tajamul
** <2021-05-06 Thu> - finish validator PR, review TvB PR
*** DONE Investigate mmap for validator
*** TODO Review Thomas' PR for ros control dash
*** 
** <2021-05-07 Fri> - Planning planning planning
*** DONE Read [[https://abyss-solutions.atlassian.net/wiki/spaces/PD/pages/1735327825/PL+Data+Processing+Summary+SW2][PL: Data Processing Summary]] through
**** TODO Fill out Stage 1: GoPro -> Processed GoPro
**** TODO Fill out Stage 3a: Image and video generation
*** DONE Prettify the cross-section area diagram
*** DONE Metashape thing for Eric
* Week starting <2021-05-10 Mon>
** <2021-05-10 Mon> - Metashape for eric, update-repositories
*** TODO try again with lower settings for Eric's thing with Metashape
*** TODO finish robotics' bersion of update_all.sh
** PI PLANNING FOR 2 DAYS
** <2021-05-13 Thu> - Metashape for Eric, CC Eval comparison, clean abyss-internal, data processing handover, build system testing
*** DONE try again with lower settings for eric's metashape
Message Eric!
*** DONE make metashape-cli save the invoking command to a text file!
*** TODO make CC eval table (on confluence page
*** DONE clean out abyss-internal
*** DONE finish data processing handover confluence page
*** TODO test the build system
First test on george to iron out major bugs
| OS           | Fresh install? |
|--------------+----------------|
| Arch         | No             |
|--------------+----------------|
| Ubuntu 18.04 | Yes            |
|              | No             |
|--------------+----------------|
| Ubuntu 20.04 | Yes            |
|              | No             |
** <2021-05-14 Fri> - Final CC eval stuff, more build system tweaks and improvements, validate sonar files
*** DONE Add some screenshots to confluence page for ContextCapture eval
*** TODO test build system and fix bugs
*** TODO add capacity to validate sonar files to robotics-validate
* Week starting <2021-05-17 Mon>
** <2021-05-17 Mon> - Keep trying with Metashape for carpark DSLR, test build system on 16.04, validate sonar files, review ADK005 report
*** TODO metashape carpark DSLR dataset
*** DONE test build system on 16.04
**** TODO install hq and ssh keys on 18.04
**** TODO install 16.04 with hq and ssh keys
*** TODO validate sonar files
*** DONE review ADK005 report
** <2021-05-18 Tue> - Email Steve, validate sonar
*** TODO Expose oculus::extract_payload() in Python to read data from binary files
**** TODO add pybind11 to dependencies in build system
**** TODO convert bad oculus file to .bin format
**** TODO chase up opencv build issue
** <2021-05-19 Wed> - LEAVE: Graduation
** <2021-05-20 Thu> - Finish sonar implementation for validator
*** TODO Sonar implementation: finish all todos, submit for review
**** Install pybind11
**** Install the compiled file to site packages
*** DONE Also ask ZSL how we should merge feature/support-validation-of-sonar-data
*** TODO check if bathymetry generation branch can be merged, submit PR with review for Lash
** <2021-05-21 Fri>
*** DONE add NON_ROS_INSTALL to root makefile in abyss-robotics
*** DONE make sure tools are built before sensors
*** TODO test full install on fresh clone VM
*** TODO Send email out to team re: update-repositories incl. how to not clobber their installs
*** TODO make new VMs with bigger maximum drive sizes
* Week starting <2021-05-24 Mon>
** <2021-05-24 Mon> - GoPro image enhancement
*** TODO Find test datasets
- lantern: /mnt/pond/datasets/abyss-internal/platypus/explorer/20210325-balickera-tunnel/imaging-run-4
- gopro:
*** TODO Determine whether anything else is necessary for image undistortion
- find existing processed outputs
- if they require processing that is not accounted for already by Fraser's doc, find out who knows what to do
*** TODO Get comfortable running the commands Fraser has provided
** <2021-05-25 Tue> - GoPro image enhancement
*** DONE Add abyss-web to update-repositories install
*** DONE generate timestamped GPS data fro david/sean
*** DONE Fix parallel image generation for platypus
*** DONE Write usage examples for enhance-lantern-images
*** DONE Complete functionality for enhance-lantern-images and test
*** TODO Implement undistortion based on Suchet's commands.txt
*** TODO Implement a 'do-all' operation for image enhancement and undistortion
** <2021-05-26 Wed> - Planning, meetings, GoPro undistortion
*** DONE Verify whether or not image enhancement produces the same size images
*** DONE Add gopro and lantern configs to abyss-robotics/configs
*** DONE Implement undistortion based on Suchet's commands.txt
*** TODO Implement a 'do-all' operation for image enhancement and undistortion
** <2021-05-27 Thu> - Wrap up GoPro undistortion
*** DONE Add a lantern config for image undistortion
*** DONE Test undistortion logic
*** DONE sort all input file finds
*** DONE try teeing log_progress
*** DONE implement individual-video-streams
*** TODO investigate whether using lantern-get's parallelisation is enough

* Week starting <2021-05-31 Mon>
** <2021-05-31 Mon> - Build system demo, read binary pointcloud into python
*** TODO Send email to tech ppl re: comma and snark
*** DONE Build system demo
Points to discuss:
**** TODO print installed at the end
**** TODO test install on 18.04
*** TODO Read binary pointcloud into Python
**** TODO Add to build system
**** TODO Make importable library
**** DONE ? Use =with ...= syntax 
**** DONE Have a generator to generate one scan at a time
**** TODO Check that Open3D can take a numpy array as a pointcloud
** <2021-06-01 Tue> - Resolve build system issues, complete reading binary pointclouds
*** DONE Add option to exclude NaN when extracting pointclouds
*** TODO Resolve build system issues
**** DONE Print installed packages at the end
**** TODO Send email to tech ppl re: comma and snark
*** DONE Read binary pointcloud into Python
**** DONE Finish doxygen
**** DONE Catch exceptions caused by struct.unpack() on less than 44 bytes
**** DONE Test on a whole directory
**** DONE Add to build system (make importable library)
**** DONE Check that Open3D can take a numpy array as a pointcloud
*** TODO Generate example data
**** DONE Lidar binary files
**** TODO YAML for the remaining data
**** TODO Move into appropriate place
*** TODO Install metashape module on buffalo
*** TODO review Zdzislaw's review
** <2021-06-02 Wed> - Resolve build system issues, build system review, metashape pyhton module
*** TODO Resolve build system issues
**** DONE Print installed packages at the end
**** TODO Try to get abyss forks of comma and snark to build
**** TODO Send email to tech ppl re: comma and snark
*** DONE Generate example data
**** DONE Lidar binary files
**** DONE YAML for the remaining data
**** DONE Move into appropriate place
*** DONE Install metashape module on buffalo
*** TODO review Zdzislaw's review
**** TODO add zstandard to dependencies
**** TODO add make uninstall to update-repositories
**** TODO add make clean to root Makefile
** <2021-06-03 Thu> - Review Zdz review, send email to tech
* Week starting <2021-06-07 Mon>
** <2021-06-07 Mon> - Prefect testing and beginning implementation
** <2021-06-08 Tue> - JJ review, MG review, robotics-stages stub implementation
*** DONE test https git clone, respond to JJ
*** TODO Review Mitch's code
*** TODO Adk zdz about make uninstall (both for update-repositories and abyss-robotics)
*** TODO Add type hints to confluence page
** <2021-06-09 Wed> - Map out SW2 scaffold
*** TODO Make the config accurate (or at least better) in terms of inputs/outputs
*** TODO see if fabric stages can handle depends as dicts
*** TODO Try dry running (see if it will even work with just input data)
*** TODO Write stage stubs, preferably with enough structure to be able to pad them out later
*** DONE Add to the lantern miro board (see JJ's messages)
*** DONE Merge code
** <2021-06-10 Thu> - Generate data for Lash
*** DONE Generate tunnel data for Lash
*** DONE Get the ball rolling with subsea processing handover
*** DONE Fix issues with Lash's PR
*** TODO stubs and hook scripts
* Week starting <2021-06-14 Mon> (Queen's birthday public holiday)
** <2021-06-15 Tue> - make stub stages for robotics-stages, write some documentation
*** DONE finish stub stages
Make sure each stage is at least reading and writing the correct set of files
Decided to can it for now, too long
*** TODO write a README for robotics-stages
*** TODO hook robotics-stages into the build system
** <2021-06-16 Wed> - Finish readme, robotics-stages build, combinational logic for JJ
*** TODO write a README for robotics-stages
Mention at the top that only the first two sections are relevant
*** TODO hook robotics-stages into the build system
*** DONE email agisoft
*** TODO and/or seqview categories
**** TODO be sure to add an example showing this
**** TODO also move lea-preprocess into abyss-robotics and rename it
** <2021-06-17 Thu> - Finish README, robotics-stages build, combinational logic
*** DONE [#A] Update documentation for BP005 processing
*** DONE [#A] hook robotics-stages into the build system
Fix remaining issues
*** DONE [#B] write a README for robotics-stages
Mention at the top that only the first two sections are relevant
*** DONE [#B] Add error messages to Makefiles
*** TODO [#C] Add any required features to lantern-preprocess
*** TODO [#C] Change behaviour of --mask in lantern-photogrammetry to take a directory name
*** TODO [#C] Remove dependencies on having an input directory from lantern-photogrammetry when --metashape-only used
*** TODO [#C] Investigate robotics-stages for LE processing
Probably a bit overkill
*** DONE and/or seqview categories
**** DONE be sure to add an example showing this
**** DONE also move lea-preprocess into abyss-robotics and rename it
** <2021-06-18 Fri> - SD cards
*** TODO Find existing SD copying code, roll into a new utility
**** TODO handle distinct port addresses with config/command line options
**** TODO verify data was copied correctly (somehow)
**** TODO Document usage and functionality
* Week starting <2021-06-21 Mon>
** <2021-06-21 Mon> - SD card testing
*** DONE Get SD card reading working reliably
*** DONE test on bisous
*** DONE print validation to file
*** DONE fix exiftool error message
GoPro just writes EXIF data poorly, nothing to be done
*** DONE test when:
- no hub connected
- different hub connected
*** DONE lantern stuff
** <2021-06-23 Wed> - Play with open3d ICP
*** TODO prepare sprint demo
Start SD transfer
*** TODO Open3D ICP
There is /point-to-point/ and /point-to-plane/ ICP, lash only ever used /point-to-point/
**** TODO try open3d example
**** TODO apply to tunel dataset
** <2021-06-24 Thu> - Start real ICP implementation
*** TODO Start filling out laser-localisation
* Week starting <2021-06-28 Mon>
** <2021-06-28 Mon> - Localisation continues
*** DONE Get ICP actually working (dangit!)
Try accumulating scans
*** DONE Do the thing from Zdz's message
** <2021-06-29 Tue> - Localisation
*** DONE Review stuff with Lash
|-------------------------------------------+-------------------------------------------|
| Transform local to global frame           | Shift the map                             |
|-------------------------------------------+-------------------------------------------|
| Fastest with single scan matching, (1:33) | Slower (2:00) for window size of 10,      |
| Slow with all scan matching(5:58)         | very slow (8:49) for a window size of 500 |
| (2:00) for a window size of 10            |                                           |
|-------------------------------------------+-------------------------------------------|
| Produces correct localisation             | Output localisation is weird but map      |
|                                           | is generated correctly so idk             |
*** DONE Make RIBF generator
Should be able to handle:
- Directories and single files
- Compressed and uncompressed
*** DONE Get input data reading correctly
*** DONE Use velocity from realsense to improve deltaTransform
*** TODO Test in a tunnel
** <2021-06-30 Wed> - Localisation
*** DONE Polishing and refining functionality, fixing bugs
*** DONE Test in a tunnel
Didn't fully work
** <2021-07-01 Thu> - Localisation
*** DONE Config wrangling
**** DONE add start and end times to global config
**** DONE handle heirarchy
*** TODO Removing unwanted points
**** TODO update platform config
*** TODO make ribf and rslidar modules use integer microseconds
*** TODO create generic python module, move functions in there and import it
*** TODO Ask questions of ZDZ
- prefix
- make uninstall
- python module for colour etc
- python module naming
- ribf
- timestamps to microseconds

** <2021-07-02 Fri> - Localisation, other small niceties
*** TODO Removing unwanted points
**** TODO update platform config
*** TODO make ribf and rslidar modules use integer microseconds
*** TODO create generic python module, move functions in there and import it
*** TODO Investigate minimal cleaning dense clouds
* Week starting <2021-07-05 Mon>
** <2021-07-05 Mon> GoPro testing in the office
** <2021-07-06 Tue> - GoPro documentation, fix build system, localisation stuff
*** DONE Complete GoPro docs
*** DONE Finish fixing build system
*** TODO Exclude localisation points
*** TODO make ribf and rslidar modules use integer microseconds
*** TODO create generic python module, move functions in there and import it
** <2021-07-07 Wed> - Polish off localisation stuff
*** DONE Exclude localisation points
**** DONE Test it works with config paths explicitly given
**** DONE check configs are installed correctly and test with installed configs
*** DONE make ribf and rslidar modules use integer microseconds
*** TODO create generic python module, move functions in there and import it
** <2021-07-08 Thu> - PR reviews, annual review prep
*** DONE REview Zdz's PR
*** TODO Finish reviewing Mitch's PR
*** TODO Prepare for performance review
*** TODO ribf-to-csv
**** TODO play with std::map separately to get a feel
** <2021-07-09 Fri> - seqview big images, ribf-to-csv multi-fields, ocn002 processing
*** TODO seqview - generate metadata and big images
* Week starting <2021-07-12 Mon>
** <2021-07-12 Mon> - BP005 processing
- ml8 bending shoe chain
  - links 1-7 (model-1.7.psx)
    - ready to go
    - marker on link 2
  - links 8-20
    - masks ready on V7
- ml8-ground-chain
  - datasets still needed, not on files.com yet
- ml8-upper-ground-chain
  - order of links unknown, just be consistent
- ml8-links-below-platform-chain
  - sparse cloud ready
  - mesh to be created
*** TODO Train V7 link segmentation
** <2021-07-13 Tue> - training Taj
*** DONE Train V7 link segmentation
*** DONE run darktable test
*** TODO document building darktable from source
*** DONE train tajamul
*** DONE continue data download
*** DONE fix lantern-photogrammetry (after darktable test)
*** TODO start slicing models (after fixing lantern-photogrammetry)
** <2021-07-14 Wed> - BP005 processing
*** DONE start slicing models (after fixing lantern-photogrammetry)
*** DONE generate textures for all links
*** TODO compare speeds of processing using SSDs vs pond
*** DONE build darktable on buffalo and document building darktable from source
*** TODO ensure lantern-photogrammetry uses images without masks
** <2021-07-15 Thu> - BP005 processing automation
*** TODO compare speeds of processing using SSDs vs pond
*** TODO ensure lantern-photogrammetry uses images without masks
*** TODO Investigate the progress callback
Should be as simple as creating a function to just print progress in metashape-cli-backend, then it can be called
*** TODO Update the process in metashape-cli to generate textured model from depth maps
*** TODO automate the process
**** TODO Work out the best way to do that
e.g. python vs bash
*** TODO processing
**** TODO ml8-ground-chain
** <2021-07-16 Fri> - BP005 processing automation
** TODO 
* Week starting <2021-07-19 Mon>
** <2021-07-19 Mon> - BP005 processing, seqview metadata
*** DONE reduce the amount of output from waiting for files
*** DONE set up bruno arch for processing
*** DONE seqview annotations
*** TODO continue processing
find how far the other one got
*** TODO generate seqview metadata
** <2021-07-20 Tue> - BP005 processing
*** TODO see how far bruno got (update spreadsheet)
*** TODO finish sourcing functions in stages-utils.sh
*** TODO write email to jj re: exporting the chain model, memory usage, etc
*** TODO Run calibration datasets on bruno
** <2021-07-21 Wed> - BP005 processing automation
*** DONE Update stages
**** DONE move more logic to =stages-utils.sh=
**** DONE update stages scripts
**** DONE execute processing
*** DONE Run processing
** <2021-07-22 Thu> - BP005 processing
*** DONE update tracker sheet
*** DONE export & slice ml8 links
*** DONE build textured models for calibration links
*** DONE generate calibration model for the 23rd
** <2021-07-23 Fri> - BP005 processing
*** DONE Download and prepare masks from V7 for ml7-bending
*** TODO compare binary and non-binary PLYs
**** file size
**** loading time (into metashape)
**** can polyworks load it?
*** TODO slice ml8 ground chain
Do this first while buffalo's metashape license isn't in use
**** TODO ask jordan how we can tell which link is which
*** TODO review Zdz's PR
*** TODO re-export models as binary
**** TODO ml8 bending shoe links 8-20
**** TODO ml8 ground chain
**** TODO ml8-upper-ground-chain
**** TODO ml8-links-below-platform
* Week starting <2021-07-26 Mon>
** <2021-07-26 Mon>
*** TODO Aug 16-18 - GHD delivery, delivery 3 weeks from 20 aug
*** TODO Nov 19 - Scottish water initial delivery (1 mo fater end of job), final delivery 3mo after end of job (20/01/2022)
** <2021-07-27 Tue> - PI PLANNING
** <2021-07-28 Wed> - PI PLANNING
** <2021-07-29 Thu> - BP005 processing, metashape-cli improvements, plan for demo
*** TODO Continue BP005 processing
*** DONE Apply improvements to metashape-cli
**** DONE Limit progress messages to 0.2% increments
**** DONE Calculate ETA
*** TODO Make a plan for lantern eye processing
*** TODO review calibration script
*** TODO add comma & snark wiki to software
** <2021-07-30 Fri> - Lantern presentation
*** DONE Prepare for lantern presentation
*** DONE Check lantern-photogrammetry still works
e.g. did changing =--import-lantern-directory= to =--import-lantern-dataset= cause any problems?
e.g. does the default routine still work?
*** TODO add stuff to Jira
*** TODO review calibration script
*** TODO add comma & snark wiki to software
* Week starting <2021-08-02 Mon>
** <2021-08-02 Mon> - BP005 manual stuff, subsea processing onboarding, comma & snark wiki, calibration script
*** DONE get up to speed on processing progress
*** DONE onboard Cici and Daniel
*** TODO place markers on links and slice links from ground chains
*** DONE add stuff to Jira
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO add comma & snark wiki to software
*** DONE install metashape on RDS
** <2021-08-03 Tue> - Debugging, onboarding
*** DONE Fix Fraser's problem
*** DONE set accuracies on remaining models and allocate work to Cici and Daniel
*** DONE place markers on links
*** TODO slice links from ground chains
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO add comma & snark wiki to software
** <2021-08-04 Wed> - Slicing
*** DONE inform eric of ROI ML etc
*** DONE Take screenshot and slice ML5 ground chain
*** TODO try to "align selected cameras" -> might improve ml8 accuracy
**** TODO duplicate chunk
**** TODO see if this works using metashape-cli 
*** TODO Slice ML8 ground chain
*** DONE only pull selected repos with --only-do in update-repositories
*** DONE robotics-validate: add check: is topic actually in bag?
This is already there, that bug is hard to find
*** DONE robotics-validate: append bag topic before magnitude below etc
*** DONE robotics-validate: print dropped image only once (it prints twice with Platypus)
Same again!
*** DONE plots are still being generated when shouldPlot is False
*** DONE email JJ
*** TODO vnc buffalo
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO add comma & snark wiki to software
** <2021-08-05 Thu> - Some slicing
*** DONE Validate link numbers using spreadsheet
**** DONE ml8 ground chain: correct link numbers in Metashape
**** DONE ml8 ground chain: correct link numbers in gimp
**** DONE ml5 ground chain: correct link numbers in Metashape
**** DONE ml5 ground chain: correct link numbers in gimp
**** DONE ml5 ground chain: correct link numbers in filenames
**** DONE ml8 upper ground chain:         correct link numbers in Metashape
**** DONE ml8 upper ground chain:         correct link numbers in filenames
**** DONE ml8 links below platform chain: correct link numbers in Metashape
**** DONE ml8 links below platform chain: correct link numbers in filenames
**** DONE ml7 bending shoe chain: check chain orientation
**** DONE ml7 bending shoe chain: check link 1 is not link 19
*** TODO Slice ML8 ground chain
*** DONE Add new metashape-cli expression for aligning cameras
**** TODO optionally: investigate adding cameras without removing the existing alignment
*** TODO ? Try reconstructing ml5 ground chain with even more cameras
*** TODO vnc buffalo
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO add comma & snark wiki to software
** <2021-08-06 Fri> - Slicing, documentation, flare-stacks model
*** TODO Slice ML8 ground chain
*** DONE fix report with Tajamul
*** DONE crop noise out of OCN002 models
**** DONE 1-20
**** DONE 1-30
**** DONE 2-25
**** DONE 2-30
**** DONE 3-20
**** DONE 3-30 - no reslice, but T needs to drag a caliper
**** DONE 4-20
**** DONE 5-20 - no reslice, but zone f in-plane right caliper is slightly off
**** DONE 5-25
*** DONE flare-stacks model
*** TODO vnc buffalo
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO add comma & snark wiki to software
* Week starting <2021-08-09 Mon>
** <2021-08-09 Mon> - fix metashape-cli, flare stacks reconstruction, docs
*** DONE fix metashape-cli
*** DONE fix bugfix branch
*** DONE Slice ML8 ground chain
Check if local copy up to date
*** DONE flare-stacks reconstruction
*** TODO vnc buffalo
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO add comma & snark wiki to software
*** TODO start a confluence page on scaling processing
**** TODO current pain points
**** TODO predicted pain points and barriers to scaling
** <2021-08-10 Tue> - start fixing bad reconstructions
*** DONE test ssh X11 forwarding after removing libxcb on george
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close
*** DONE update /is good enough/ status on tracker
*** TODO copy ml7 bending shoe chain back to pond
*** TODO fix texture on ml8-15 ocn002 model
*** TODO investigate fixes for bad reconstructions
Set up and conduct a proper test, with documentation
**** TODO do quality settings (lower qual depth maps) help or hurt?
**** TODO would using masks (for depth map generation too?) help in areas of bubbling and noise?
**** TODO does chromatic aberration correction actually hinder it?
**** TODO priority annotations?
*** TODO Improve cross-section area script -> abyss-robotics examples
**** TODO Inspect data format from Taj
**** TODO Implement robust checking for bad points, other cross-sections, etc
*** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
*** TODO =robotics-stages= improvements
**** TODO robotics-stages: add chunk id global configurable
**** TODO add a robotics-stages stage for incremental alignment
**** TODO add a robotics-stages stage for disabling innacurate scalebars
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO start a confluence page on scaling processing
**** TODO current pain points
**** TODO predicted pain points and barriers to scaling
*** TODO add comma & snark wiki to software
** <2021-08-11 Wed> - fix bad reconstructions, robotics-validate improvements
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close
*Algo:*
- find first image
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
*** DONE copy ml7 bending shoe chain back to pond
*** DONE fix texture on ml8-15 ocn002 model
*** TODO investigate fixes for bad reconstructions
Set up and conduct a proper test, with documentation
**** TODO do quality settings (lower qual depth maps) help or hurt?
**** TODO would using masks (for depth map generation too?) help in areas of bubbling and noise?
**** TODO does chromatic aberration correction actually hinder it?
**** TODO priority annotations?
*** TODO Improve cross-section area script -> abyss-robotics examples
**** TODO Inspect data format from Taj
**** TODO Implement robust checking for bad points, other cross-sections, etc
*** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
*** TODO =robotics-stages= improvements
**** TODO robotics-stages: add chunk id global configurable
**** TODO add a robotics-stages stage for incremental alignment
**** TODO add a robotics-stages stage for disabling innacurate scalebars
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO start a confluence page on scaling processing
**** TODO current pain points
**** TODO predicted pain points and barriers to scaling
*** TODO add comma & snark wiki to software
** <2021-08-12 Thu> - robotics-validate improvements, check bad reconstructions
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close

*Algo:*
- find first image *(f)*
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
  - this is the /reference timestamp/
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
 
***** DONE read data in correctly

*** TODO investigate fixes for bad reconstructions
Set up and conduct a proper test, with documentation
**** TODO do quality settings (lower qual depth maps) help or hurt?
**** TODO would using masks (for depth map generation too?) help in areas of bubbling and noise?
**** TODO does chromatic aberration correction actually hinder it?
**** TODO priority annotations?
*** DONE email suchet
*** TODO transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
*** TODO ask lash about localisation
*** TODO Improve cross-section area script -> abyss-robotics examples
**** TODO Inspect data format from Taj
**** TODO Implement robust checking for bad points, other cross-sections, etc
*** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
*** TODO =robotics-stages= improvements
**** TODO robotics-stages: add chunk id global configurable
**** TODO add a robotics-stages stage for incremental alignment
**** TODO add a robotics-stages stage for disabling innacurate scalebars
*** TODO review calibration script
*** TODO start a confluence page re: transitioning to python
*** TODO start a confluence page on scaling processing
**** TODO current pain points
**** TODO predicted pain points and barriers to scaling
*** TODO add comma & snark wiki to software
** <2021-08-13 Fri> - robotics-validate improvements, fix bad reconstructions
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close

*Algo:*
- find first image *(f)*
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
  - this is the /reference timestamp/
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
 
***** DONE read data in correctly

*** TODO investigate fixes for bad reconstructions
Set up and conduct a proper test, with documentation
**** TODO do quality settings (lower qual depth maps) help or hurt?
**** TODO would using masks (for depth map generation too?) help in areas of bubbling and noise?
**** TODO does chromatic aberration correction actually hinder it?
**** TODO priority annotations?
*** DONE try to improve ml8-ground-chain
We can't seem to build a big dense cloud, so it looks like our options are
*** DONE fix LP bug
*** TODO transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
*** DONE ask lash about localisation
*** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
*** TODO =robotics-stages= improvements
**** DONE robotics-stages: add chunk id global configurable
**** TODO add a robotics-stages stage for incremental alignment
**** TODO add a robotics-stages stage for disabling innacurate scalebars
*** TODO review calibration script
*** DONE start a confluence page re: transitioning to python
*** DONE start a confluence page on scaling processing
**** TODO current pain points
**** TODO predicted pain points and barriers to scaling
*** TODO add comma & snark wiki to software
* Week starting <2021-08-16 Mon>
** <2021-08-16 Mon> - BP005 finalisation
*** DONE make /"old link numbers"/ column on tracker spreadsheet
*** DONE get daniel going with cleaning
*** DONE copy ml7 back to pond
*** DONE update example stages config
*** DONE push code to git
*** DONE fix textures
**** DONE write small utility to correctly rename 3D models
**** DONE ml8 ground chain links 4 and 5
**** DONE ml5 ground chain
*** DONE transfer OCN002 to files.com
*** DONE build texture for ml8-ground-chain
Fix metashape-cli
*** TODO transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
*** TODO lash's localisation PR
*** TODO ml6-bending-shoe link below with masks doesn't seem to have masks?
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO install configs to /etc and allow user to specify
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close

*Algo:*
- find first image *(f)*
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
  - this is the /reference timestamp/
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
 
***** DONE read data in correctly
*** TODO *tech debt* (longer term, opportunistic stuff)
**** TODO message Jackson
**** TODO look at positions that want a PhD on seek
**** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
**** TODO =robotics-stages= improvements
***** DONE robotics-stages: add chunk id global configurable
***** TODO add a robotics-stages stage for incremental alignment
***** TODO add a robotics-stages stage for disabling innacurate scalebars
**** TODO review calibration script
**** TODO add comma & snark wiki to software
** <2021-08-17 Tue> - BP005 finalisation
*** TODO gbbv
**** TODO unzip Jordan's model
**** TODO compare accuracies
**** TODO reconstruct without interpolation?
*** TODO fix ml7 textures
*** TODO make sure there is a low-poly version of every chain for Usman
*** TODO transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
can't seem to get this to work?
*** DONE platypus process overview
**** TODO prepare examples of data products
*** TODO lash's localisation PR
*** TODO ml6-bending-shoe link below with masks doesn't seem to have masks?
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO install configs to /etc and allow user to specify
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close

*Algo:*
- find first image *(f)*
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
  - this is the /reference timestamp/
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
 
***** DONE read data in correctly
*** TODO *tech debt* (longer term, opportunistic stuff)
**** TODO message Jackson
**** TODO look at positions that want a PhD on seek
**** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
**** TODO =robotics-stages= improvements
***** DONE robotics-stages: add chunk id global configurable
***** TODO add a robotics-stages stage for incremental alignment
***** TODO add a robotics-stages stage for disabling innacurate scalebars
**** TODO review calibration script
**** TODO add comma & snark wiki to software
** <2021-08-18 Wed> - BP005 finalisation
*** TODO gbbv
**** DONE unzip Jordan's model
**** TODO compare ground truths to Jordan's model with Tajamul
**** TODO cut half the images out of one of the half chunks
**** TODO reconstruct without interpolation?
**** DONE export a good model for T
*** DONE fix ml7 textures
*** DONE make sure there is a low-poly version of every chain for Usman
*** TODO transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
can't seem to get this to work? - I think there's some irrelevant data here though, need to clean the bigbrains scratch directory and just keep the important stuff
*** TODO lash's localisation PR
*** TODO ml6-bending-shoe link below with masks doesn't seem to have masks?
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO install configs to /etc and allow user to specify
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close

*Algo:*
- find first image *(f)*
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
  - this is the /reference timestamp/
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
 
***** DONE read data in correctly
*** TODO *tech debt* (longer term, opportunistic stuff)
**** TODO make usage examples only print with verbose for lantern tools
**** TODO message Jackson
**** TODO look at positions that want a PhD on seek
**** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
**** TODO =robotics-stages= improvements
***** DONE robotics-stages: add chunk id global configurable
***** TODO add a robotics-stages stage for incremental alignment
***** TODO add a robotics-stages stage for disabling innacurate scalebars
**** TODO review calibration script
**** TODO add comma & snark wiki to software
** <2021-08-19 Thu> - BP005 finalisation
*** DONE make sure there is a low-poly version of ml8 8-20 for Usman
*** DONE run all ocn002 calibration models
Check with Mitch first, is he already doing this? - *yes*
*** DONE fix out-of-order ribf and rslidar libraries
*** DONE [#A] lash's localisation PR
*** DONE [#A] gimp script levels adjust
*** TODO [#A] try to fix bad grip zones
**** DONE ml6-bending-shoe-chain-below: dense cloud
**** DONE ml6-bending-shoe-chain-above: dense cloud
**** TODO ml6-bending-shoe-chain-above: model
**** DONE ml5-bending-shoe-chain-below: dense cloud
**** TODO ml5-bending-shoe-chain-below: model
**** DONE ml8-bending-shoe-chain-link-8: separate seqview annotation
**** TODO ml8-bending-shoe-chain-link-8: dense cloud
**** TODO ml8-bending-shoe-chain-link-8: model
*** TODO [#B] transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
can't seem to get this to work? - I think there's some irrelevant data here though, need to clean the bigbrains scratch directory and just keep the important stuff
*** TODO [#C] archive stuff for jeff
*** TODO gbbv
**** DONE unzip Jordan's model
**** TODO compare ground truths to Jordan's model with Tajamul
**** TODO cut half the images out of one of the half chunks
**** TODO reconstruct without interpolation?
**** DONE export a good model for T
*** TODO ml6-bending-shoe link below with masks doesn't seem to have masks?
*** TODO robotics-validate improvements
**** TODO plot dropped images
**** TODO install configs to /etc and allow user to specify
**** TODO check if matplotlib can deal with large amounts of data
**** TODO make plots bigger
**** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close

*Algo:*
- find first image *(f)*
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
  - this is the /reference timestamp/
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
 
***** DONE read data in correctly
*** TODO *tech debt* (longer term, opportunistic stuff)
**** TODO make usage examples only print with verbose for lantern tools
**** TODO make lantern-photogrammetry not delete every fucking thing
**** TODO message Jackson
**** TODO look at positions that want a PhD on seek
**** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
**** TODO =robotics-stages= improvements
***** DONE robotics-stages: add chunk id global configurable
***** TODO add a robotics-stages stage for incremental alignment
***** TODO add a robotics-stages stage for disabling innacurate scalebars
**** TODO review calibration script
**** TODO add comma & snark wiki to software
** <2021-08-19 Thu> - BP005 finalisation
*** DONE 20 link inspection video for JJ
*** DONE uncertainty analysis
**** DONE how to do?
And can it all be done today
operations/depricated/
**** DONE review and improve distance to object script
**** DONE set up uncertainty analysis spreadsheet
***** DONE BP005
***** DONE OCN002
**** DONE Fill out scale bar distances from val units
***** DONE BP005
***** DONE get mitch to do OCN002
**** DONE pick 3 models from:
***** DONE BP005
***** DONE OCN002
**** DONE run distance to object on:
***** DONE BP005 val units
***** DONE BP005 models
***** DONE OCN002 val units
***** DONE OCN002 models
**** DONE Complete Spreadsheets for:
***** DONE BP005
***** DONE OCN002
*** DONE [#A] try to fix bad grip zones
**** DONE ml6-bending-shoe-chain-below: dense cloud
**** DONE ml6-bending-shoe-chain-above: dense cloud
**** DONE ml6-bending-shoe-chain-above: model
**** DONE ml6-bending-shoe-chain-above: texture
**** DONE ml6-bending-shoe-chain-above: export
**** DONE ml6-bending-shoe-chain-above: copy to reporting
**** DONE ml5-bending-shoe-chain-below: dense cloud
**** DONE ml5-bending-shoe-chain-below: rerun model
**** DONE ml5-bending-shoe-chain-below: texture
**** DONE ml8-bending-shoe-chain-link-8: separate seqview annotation
**** DONE ml8-bending-shoe-chain-link-8: dense cloud
**** DONE ml8-bending-shoe-chain-link-8: model
* Week starting <2021-08-23 Mon>
** <2021-08-23 Mon> - BP005 wrap-up, GBBV, start on Platypus
*** DONE Wrap up BP005 documentation and PR
*** DONE gbbv
**** DONE unzip Jordan's model
**** DONE compare ground truths to Jordan's model with Tajamul
**** DONE export a good model for T
**** DONE get Tajamul started
*** TODO GHD007 processing
** <2021-08-24 Tue> - GHD007 processing
*** DONE start working with Daniel and Cici
** <2021-08-25 Wed>
*** TODO talk to:
**** TODO Rolfe
**** TODO Eric - msg about what he wants
**** TODO Adam - 
**** TODO Jordan - bonus
** <2021-08-26 Thu> - GHD007
** <2021-08-27 Fri> - GHD007
* Week starting <2021-08-30 Mon>
** <2021-08-30 Mon> - GHD007 processing, help Fraser
*** DONE Fix GoPro SD card tool bug
**** DONE talk to Fraser
**** DONE fix up code on branch
*** TODO GHD007 Processing
**** TODO [#B] Generate video
*** DONE *tech debt* (longer term, opportunistic stuff)
**** DONE [#B] transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
can't seem to get this to work? - I think there's some irrelevant data here though, need to clean the bigbrains scratch directory and just keep the important stuff
ask Cici where the data is
** <2021-08-31 Tue> - GHD007 processing
** <2021-09-01 Wed> - GHD007
*** DONE Make Platypus images actual jpgs
*** DONE Ask imran about seqview deployment
*** TODO Convert GBBV to step if possible
** <2021-09-02 Thu> - GHD007 localisation, final video stuff
** <2021-09-03 Fri> - GHD007 localisation, hopefully pointclouds
*** DONE Push updated seqview video to production
*** TODO Add diff check against reference frame timeline to generate frame timeline script
*** TODO Localisation
**** TODO View platypus pointclouds to establish where X, Y and Z are
**** TODO Modify "view" routine to show pointcloud after expected transformation
**** TODO Add capability to use pre-extracted data for speed
**** DONE Try without ribf data, why is there a huge jump??
Running out of scans!
*** TODO Bathymetry
**** TODO Check if Zdz's PR works
*** TODO *tech debt* (longer term, opportunistic stuff)
**** DONE [#B] transform points
/mnt/rapid/scratch/bigbrains/flare-stacks - data is here
can't seem to get this to work? - I think there's some irrelevant data here though, need to clean the bigbrains scratch directory and just keep the important stuff
ask Cici where the data is
**** TODO [#C] archive stuff for jeff
**** TODO Are masks imported correctly?
**** TODO save cross-section renaming script
**** TODO improve gitconfig with zdz's stuff (in scratch)
**** TODO robotics-validate improvements
***** TODO plot dropped images
***** TODO install configs to /etc and allow user to specify
***** TODO check if matplotlib can deal with large amounts of data
***** TODO make plots bigger
***** TODO validate camera timestamps more cleverly
- set expected framerate and tolerance in config
- find dropped frames based on the above
- plot per-camera time since previous frame
- use that to identify frames that are too close

*Algo:*
- find first image *(f)*
  - find literal earliest and look within 2*jitter for other cameras, average if there are any
  - this is the /reference timestamp/
- while there are still images in at least one camera:
  - for camera in cameras:
    - if at end of list:
      - record a missed frame
    - look for index of timestamp most closely matching desired timestamp
    - if no match:
      - if next timestamp too far ahead:
        - *record a miss*
      - else (next timestamp too early):
        - while next timestamp < expected timestamp:
          - *record an unexpected frame*
          - increment index
    - else (there was a match):
      - if index moved more than one step:
        - for index after previous and before match:
          - *record an unexpected frame*
      - update index
      - return/save new timestamp (for averaging)
  - Average timestamps and update expected timestamp
 
***** DONE read data in correctly
**** TODO make usage examples only print with verbose for lantern tools
**** TODO make lantern-photogrammetry not delete every fucking thing
**** TODO message Jackson
**** TODO look at positions that want a PhD on seek
**** TODO make a metashape-cli operation to disable all scalebars with abs(error) >= 0.001
**** TODO =robotics-stages= improvements
***** DONE robotics-stages: add chunk id global configurable
***** TODO add a robotics-stages stage for incremental alignment
***** TODO add a robotics-stages stage for disabling innacurate scalebars
**** TODO review calibration script
**** TODO add comma & snark wiki to software
**** TODO fix combinational seqview category logi
* Week starting <2021-09-06 Mon>
** <2021-09-06 Mon> - Fix localisation bugs, symlink frames
*** TODO Add diff check against reference frame timeline to generate frame timeline script
*** TODO write script to match chainage into frame timeline
*** TODO write script to add to annotations
*** TODO Fix localisation issues
**** DONE cull scans correctly
**** TODO Extract only relevant data to ribf
** <2021-09-08 Wed> - Finish remaining tools, continue localisation
*** DONE Create localisation merging tool
*** DONE Clean up daniel's chainage tool
*** DONE Finish LiDAR tool
*** DONE seqview category modifications for roshanthi
*** TODO update platform config and rerun localisation
*** TODO Look at raw velocity from realsense
**** TODO If it is smoother, use that instead of the pose
**** TODO Work out why adding ribf just makes it spin
** <2021-09-09 Thu> - Fix localisation, Metashape for Toby
*** TODO Get localisation working
**** TODO Remove initial transform of pointclouds
**** TODO Print x,y,z,roll,pitch,yaw
*** TODO brighten images
* Week starting <2021-09-13 Mon>
** <2021-09-13 Mon> - Localisation improvements
** <2021-09-14 Tue> - GHD007
*** TODO Rope chainage to deployment
*** TODO Correct for heading drift
**** To tell Fraser
Heading drift is an issue, are sensors close to high current cables?
**** TODO Break tunnel into sections
They may individually be straight
**** TODO Reduce iterations further? Drop threshold in rocky sections?
**** TODO Point to plane?
**** TODO Average between given tunnel heading and heading from IMU
**** TODO Filter out bad deltaPose
*** TODO Write list of things for rolfe
*** TODO Reconstruct sonar
**** TODO Update from_body transform
** <2021-09-17 Fri>
*** TODO email
*** TODO more iterations
*** TODO lower threshold
*** TODO slightly smaller dt
*** TODO allow pitch and roll
Do 3 on the discontinuity and 3 on the 
*** TODO maximum ICP yaw change (relative to dead reckoning)
* Week starting <2021-09-20 Mon>
** <2021-09-20 Mon> - GHD007
*** TODO Try starting one or two scans further in advance
*** DONE 40 ish iterations -> good enough for both?
*** DONE Allow only like 10% of the pitch/roll that ICP produces. Any improvement?
*** DONE Use true dt from delta timestamp, not dt from config
*** DONE If ICP does not converge, jump to next scan
*** TODO Remove ghosting - is there a tool?
* Week starting <2021-09-27 Mon>
** <2021-09-28 Tue> - GHD007 and lots of meetings
** <2021-09-29 Wed> - Catch up on OCN003 kickoff, GHD007
*** TODO Speed up localisation
**** TODO Try to integrate =abyss.bedrock.io= rather than the =rslidar= library
- How much faster?
- Does ribf need a similar thing?
**** TODO Watch OCN003 kickoff
** <2021-09-30 Thu> - OCN003 kickoff, final rocky section
*** TODO Make confluence page for LiDAR and sonar reconstructions
**** TODO send Lash a link to that
**** DONE run section 6 sonar
*** TODO watch OCN003 kickoff
*** DONE submit leave
*** DONE image-stream-merge thing
*** DONE see if --view works over ssh with glfw installed
*** TODO fix the thing stan found
*** DONE localise final rocky section
*** DONE polish section 6 for submission
**** DONE Load clouds in CC
**** DONE Clean as required
**** DONE Export as PLY
**** DONE Open in meshlab
**** DONE export as OBJ
* Week starting <2021-10-04 Mon> (Labour day public holiday)
** <2021-10-05 Tue> - Help with OCN003, GHD007 demob, prep for handovers
*** TODO GHD007 demob
**** TODO Copy data back to rapid
*** DONE ml7 model from dense cloud
*** DONE review Mitch's PR
*** TODO Create/update confluence pages before handovers
** <2021-10-06 Wed> - GHD007 wrap-up/debrief
*** DONE GHD007 debrief meeting
*** DONE Create/update confluence pages before handovers
**** DONE GHD007 - add important utils from projects repo
**** DONE Platypus Data Processing - link to GHD007
**** DONE Lantern Eye Data Processing - link to BP005
*** TODO Find which parameters need to change to stop Metashape from being killed
*** DONE Look at Lash's PR
** <2021-10-07 Thu> - faster localisation parsing
*** TODO Write script to:
- extract rslidar bin
- extract ribf
- create localisation bins from ribf
*** TODO Improve localisation parsing speed
*** TODO Clean code and submit for review
* Week starting <2021-10-11 Mon>
** <2021-10-11 Mon> - Localisation improvements
** <2021-10-12 Tue> - PI 1, OCN003 meeting, Fraser's changes to PSC
** <2021-10-13 Wed> - PI 2, Changes to PSC, OCN003 ml2
** <2021-10-14 Thu> - Continuous leraning, PSC, OCN003 uncertainty
*** DONE OCN003 Uncertainty Analysis
**** TODO Make distance to asset script print rms errors
Not possible :(
**** DONE Update/improve documentation if necessary
*** TODO PSC improvements
- Don't forget to add the transparency!
- Then try cv-cat overlay
- If that doesn't work, try ffmpeg overlay
*** TODO Start working on Corrosion diff tool
** <2021-10-15 Fri> - Final PSC stuff, OCN003 uncertainty wrap-up, Start continuous learning
*** DONE OCN003 Uncertainty Analysis
**** DONE Move video to correct place on gdrive
**** DONE Change to mm
**** DONE Submit PR for distance-to-model
*** TODO Final PSC stuff
**** DONE Make a very cut down file to test on
**** DONE Submit image-stream-merge PR
**** DONE Make it not need to be C-c'ed to finish the video
**** DONE Clean up temp files
**** TODO Update --help with new --view stuff
